{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "407d74ec",
   "metadata": {},
   "source": [
    "<h1>Gradient Boosting</h1>\n",
    "<p>method composed of naive model and cycle</p>\n",
    "<ol>\n",
    "    <h2>naive model</h2>\n",
    "    <li> initializing the ensemble with a single model.<br>it is ok that predictions of this sigle model are inaccuratee.</li>\n",
    "    <h2> cycle </h2>\n",
    "    <li> generate predictions for each observation with the current ensemble<br>predictions are used to calculate a loss function</li>\n",
    "    <li>fit a new model that will be added to the ensemble by using loss function<br>examine and determine the parameters in order for new model added to ensemble to reduce the loss<br>we use <b>gradient descent</b> on this loss function to determine the parameters</li>\n",
    "    <li>we add the new model to the ensemble</li>\n",
    "    <li>repeat  2~4</li>\n",
    "    </ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "19c66ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data = pd.read_csv(\"melb_data.csv\")\n",
    "data.dropna(subset = [\"Price\"], axis = 0, inplace = True)\n",
    "y_full = data.Price\n",
    "X_full = data.drop(\"Price\",axis = 1)\n",
    "\n",
    "X_train_full, X_valid_full, y_train, y_valid = train_test_split(X_full,y_full, train_size = 0.8, random_state = 0)\n",
    "cols = [\"Rooms\",'Distance','Landsize','BuildingArea','YearBuilt']\n",
    "\n",
    "X = data[cols]\n",
    "y = data.Price\n",
    "\n",
    "X_train, X_valid, y_train,y_valid = train_test_split(X,y,train_size =0.8, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4404faf2",
   "metadata": {},
   "source": [
    "<h1>XGBoost</h1>\n",
    "<p><b>extreme gradient boosting</b></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bb0c2685",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "             colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "             importance_type='gain', interaction_constraints='',\n",
       "             learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
       "             min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "             n_estimators=100, n_jobs=8, num_parallel_tree=1, random_state=0,\n",
       "             reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
       "             tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from xgboost import XGBRegressor\n",
    "\n",
    "my_model = XGBRegressor()\n",
    "my_model.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d56643c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "236021.00835615335\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "predictions = my_model.predict(X_valid)\n",
    "print( mean_absolute_error(predictions,y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dd52e4c",
   "metadata": {},
   "source": [
    "<p>as avobe, XGBRegressor has a lot of paramter<br></p>\n",
    "\n",
    "<h1>Parameter Tuning</h1>\n",
    "<p>some example of paramters</p>\n",
    "<ul>\n",
    "    <li>n_estimators\n",
    "        <ol>\n",
    "            <li>haw many times to go through the modeling cycle / how many models added to ensemble</li>\n",
    "            <li>if too low, underfitting</li>\n",
    "            <li>if too high, overfitting</li> \n",
    "   </li>\n",
    "    <li>learning_rate\n",
    "        <ol>\n",
    "            <li>before adding each predictions, we can multiply the predictions from each model by a small number(this number is learning_rate)</li>\n",
    "    </li>\n",
    "    <li>early_stopping_rounds\n",
    "        <ol>\n",
    "            <li>automatically find the ideal value for n_estimators.</li>\n",
    "            <li> thanks to early stopping, the model stops iterating when the validation score stops improving </li>\n",
    "            <li> usually it is good way to set high n_estimators and use early_stopping_rounds</li>\n",
    "            <li> should use eval_set in useing early_stopping_rounds</li>\n",
    "   </li>\n",
    "    <li>n_jobs\n",
    "        <ol>\n",
    "            <li>on larger datasets, setting n_jobs is sutable</li>\n",
    "            <li>the number of cores of CPU on the machine</li>\n",
    "    \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "25bdc14b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "248417.43546345728\n"
     ]
    }
   ],
   "source": [
    "model1 = XGBRegressor(n_estimators = 500)\n",
    "model1.fit(X_train, y_train)\n",
    "preds1 = model1.predict(X_valid)\n",
    "print(mean_absolute_error(preds1,y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b70a7025",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "238594.2109892765\n"
     ]
    }
   ],
   "source": [
    "model1 = XGBRegressor(n_estimators = 500)\n",
    "model1.fit(X_train, y_train,early_stopping_rounds=5, eval_set = [(X_valid, y_valid)],verbose = False)\n",
    "preds1 = model1.predict(X_valid)\n",
    "print(mean_absolute_error(preds1,y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0213e48d",
   "metadata": {},
   "source": [
    "<p>verbose --- </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d98f2808",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242422.7209131075\n"
     ]
    }
   ],
   "source": [
    "model1 = XGBRegressor(n_estimators = 500, learning_rate = 0.05)\n",
    "model1.fit(X_train, y_train,early_stopping_rounds=5, eval_set = [(X_valid, y_valid)],verbose = False)\n",
    "preds1 = model1.predict(X_valid)\n",
    "print(mean_absolute_error(preds1,y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8b30bccc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242422.7209131075\n"
     ]
    }
   ],
   "source": [
    "model1 = XGBRegressor(n_estimators = 10000, learning_rate = 0.05, n_jobs = 4)\n",
    "model1.fit(X_train, y_train,early_stopping_rounds=5, eval_set = [(X_valid, y_valid)],verbose = False)\n",
    "preds1 = model1.predict(X_valid)\n",
    "print(mean_absolute_error(preds1,y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "219fb400",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
